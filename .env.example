# =============================================================================
# Open Notebook Configuration
# Copy this file to .env and customize your settings.
# =============================================================================

# -----------------------------------------------------------------------------
# 1. SERVER CONFIGURATION (服务器配置)
# -----------------------------------------------------------------------------

# Server listening port (default: 8080)
# 服务器监听端口
SERVER_PORT=8080

# Server bind address (default: 0.0.0.0 to listen on all interfaces)
# 服务器绑定地址
SERVER_HOST=0.0.0.0

# Vector Store backend type
# 向量数据库类型
# Valid values (可选值): sqlite, duckdb, supabase, postgres, redis, memory
VECTOR_STORE_TYPE=sqlite

# Allow deleting resources (notebooks, sources) via the UI
# 是否允许在界面上删除资源
ALLOW_DELETE=true

# Allow creating multiple notes of the same type (e.g., multiple summaries) in one notebook
# 是否允许在一个笔记本中创建多个同类型的笔记
ALLOW_MULTIPLE_NOTES_OF_SAME_TYPE=true

# Maximum context length for LLM processing (in characters)
# LLM 处理的最大上下文长度（字符数），用于防止超出 Token 限制
MAX_CONTEXT_LENGTH=100000

# -----------------------------------------------------------------------------
# 2. DATA & STORAGE (数据与存储)
# -----------------------------------------------------------------------------

# Path to the SQLite vector database file (used when VECTOR_STORE_TYPE=sqlite)
# SQLite 向量数据库文件路径
SQLITE_PATH=./data/vector.db

# Path to the main application database file (checkpoints, notebooks metadata)
# 主应用程序数据库文件路径（存储检查点、笔记本元数据等）
STORE_PATH=./data/checkpoints.db

# Supabase Configuration (Used when VECTOR_STORE_TYPE=supabase)
# Supabase 配置
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-anon-key

# PostgreSQL Configuration (Used when VECTOR_STORE_TYPE=postgres)
# PostgreSQL 配置
POSTGRES_URL=postgres://user:password@localhost:5432/notebook

# Redis Configuration (Used when VECTOR_STORE_TYPE=redis)
# Redis 配置
REDIS_URL=redis://localhost:6379

# -----------------------------------------------------------------------------
# 3. AI MODELS - EMBEDDING (RAG 嵌入模型)
# -----------------------------------------------------------------------------

# Provider for generating embeddings.
# Embedding 模型提供商
# Valid values: google, ollama
EMBEDDING_PROVIDER=google

# Specific model name for embeddings.
# Embedding 模型名称
# For Google: text-embedding-004
# For Ollama: nomic-embed-text
EMBEDDING_MODEL=text-embedding-004

# -----------------------------------------------------------------------------
# 4. AI MODELS - IMAGE GENERATION (图片生成)
# -----------------------------------------------------------------------------

# Model used for generating images (Slides, Infographics).
# 用于生成图片（幻灯片、信息图）的模型
# Options:
# - gemini-2.5-flash-image-preview (Nano Banana): Faster, higher free quota.
# - gemini-3-pro-image-preview: Higher quality, lower quota.
IMAGE_MODEL=gemini-2.5-flash-image-preview

# -----------------------------------------------------------------------------
# 5. AI MODELS - CHAT & GENERATION (对话与生成)
# -----------------------------------------------------------------------------

# Main provider for chat and content generation.
# 用于对话和生成的主模型提供商
# Options: openai, ollama
CHAT_PROVIDER=openai

# Specific model name for chat and generation.
# 用于对话和生成的具体模型名称
# Examples: qwen3-max, gpt-4o, llama3.2, deepseek-v3
CHAT_MODEL=qwen3-max

# -----------------------------------------------------------------------------
# 6. AGENT & RAG PARAMETERS (Agent 与 RAG 参数)
# -----------------------------------------------------------------------------

# Maximum number of source documents to retrieve for RAG
# RAG 检索时获取的最大源文档数量
MAX_SOURCES=5

# Text chunk size for splitting documents (in characters)
# 文档切片大小（字符数）
CHUNK_SIZE=1000

# Overlap between text chunks to maintain context (in characters)
# 文档切片重叠大小
CHUNK_OVERLAP=200

# -----------------------------------------------------------------------------
# 6. FEATURE FLAGS (功能开关)
# -----------------------------------------------------------------------------

# Enable Microsoft Markitdown for converting PDF/DOCX/PPTX/XLSX to Markdown
# 开启 Markitdown 支持（用于转换 PDF/Office 文档）
# Requires 'markitdown' CLI tool installed.
ENABLE_MARKITDOWN=true

# Enable Podcast generation feature
# 开启播客生成功能
ENABLE_PODCAST=true

# Voice model for Podcast generation (OpenAI TTS model)
# 播客生成的语音模型
PODCAST_VOICE=alloy

# -----------------------------------------------------------------------------
# 7. GOOGLE GEMINI CONFIGURATION
# -----------------------------------------------------------------------------

# API Key for Google Gemini services (Required for Embedding if google, and Image Generation)
# Google Gemini API 密钥
GOOGLE_API_KEY=

# -----------------------------------------------------------------------------
# 8. OPENAI CONFIGURATION (Primary Chat/Generation)
# -----------------------------------------------------------------------------

# OpenAI API Key (Required for standard chat and generation)
# OpenAI API 密钥
OPENAI_API_KEY=

# Custom OpenAI Base URL (optional, e.g., for proxies)
# 自定义 OpenAI Base URL（可选，例如使用代理时）
OPENAI_BASE_URL=

# OpenAI Model to use for chat and generation (Supports multiple comma-separated models)
# 用于对话和生成的 OpenAI 模型（支持多个逗号分隔的模型，这些模型会标注为 Env Config）
OPENAI_MODEL=gpt-4o-mini,gpt-4o

# -----------------------------------------------------------------------------
# 9. OLLAMA CONFIGURATION (Local Inference)
# -----------------------------------------------------------------------------

# Ollama Server URL
# Ollama 服务地址 (Docker 内部访问宿主机需使用 host.docker.internal)
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Ollama Model to use (Supports multiple comma-separated models)
# 使用的 Ollama 模型名称（支持多个逗号分隔的模型）
OLLAMA_MODEL=llama3.2

# -----------------------------------------------------------------------------
# 10. TRACING & DEBUGGING (LangSmith)
# -----------------------------------------------------------------------------

# LangChain API Key for tracing (optional)
# LangSmith Tracing API 密钥（可选）
LANGCHAIN_API_KEY=your-langsmith-key

# LangChain Project name
# LangSmith 项目名称
LANGCHAIN_PROJECT=open-notebook